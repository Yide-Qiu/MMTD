
# MMM-TTA: Multi-Probe Benchmark for Maritime Multi-Object Tracking and Trajectory Association

[![Paper](https://img.shields.io/badge/arXiv-Paper-31AE8A)]()
[![Dataset](https://img.shields.io/badge/Docs-MMTDS_Dataset-0089D6)](https://yide-qiu.github.io/Pages_MMMTAA_Dataset/)
[![Download Dataset](https://img.shields.io/badge/Download-Data-10B981)](https://pan.quark.cn/s/42ff735ebab5)
[![Code](https://img.shields.io/badge/Code-Data-0089D6)](https://github.com/Yide-Qiu/MMTD/)

Official implementation of the first dynamic observation heterogeneous constellation-based maritime multi-object tracking benchmark.

## Key Contributions

### ğŸŒŸ MMM-TSS Simulation System
- First dynamic observation constellation-based trajectory simulation system
- Implements **Walker-Integrated probe groups** (128 medium-altitude + 72 low-altitude probes)
- Features adaptive spatiotemporal registration and multi-probe resampling
- Supports radar (0-800m precision) and electronic reconnaissance (0-10km precision) sensors

### ğŸš¢ MMTDS Dataset Suite
| Dataset        | Objects | Trajectory Points | Sensor Ratio (Radar/ER) | Resolution | 
|----------------|---------|-------------------|-------------------------|------------|
| MMTDS-sim      | 17,967  | 5.0M GT / 9.9M ER | 2.67% / 99.96%          | 100m       |
| MMTDS-ais      | 7,970   | 10.5M mixed       | 12.71% / 99.98%         | Real-world |
| MMTDS-[6 others]| 1,256-8,002 | 25K-505K    | 7-35% / 71-97%       | 0.92m-1km  |

### ğŸ† Benchmark Performance
| Model       | MMTDS-sim (HOTA/DetA/AssA/IDF1)            | MMTDS-satmtb (HOTA/DetA/AssA/IDF1)         | MMTDS-ootb (HOTA/DetA/AssA/IDF1)           | MMTDS-otb100 (HOTA/DetA/AssA/IDF1)         |
|-------------|--------------------------------------------|---------------------------------------------|---------------------------------------------|---------------------------------------------|
| ByteTrack   | 17.80Â±0.23 | 23.72Â±0.19 | 13.42Â±0.31 | 17.65Â±0.27 | 25.14Â±0.18 | 25.99Â±0.22 | 24.50Â±0.29 | 41.55Â±0.33 | 33.05Â±0.28 | 21.55Â±0.24 | 50.97Â±0.37 | 35.07Â±0.26 | 41.30Â±0.31 | 30.24Â±0.23 | 57.13Â±0.42 | 46.50Â±0.39 |
| OCSORT      | 10.80Â±0.18 | 20.96Â±0.21 | 5.60Â±0.12  | 10.50Â±0.15 | 25.56Â±0.27 | 29.61Â±0.32 | 22.24Â±0.25 | 42.07Â±0.36 | 36.75Â±0.29 | 25.87Â±0.23 | 52.73Â±0.41 | 35.99Â±0.33 | 36.30Â±0.28 | 31.95Â±0.26 | 42.29Â±0.34 | 36.48Â±0.31 |
| HybridSORT  | 13.98Â±0.22 | 23.23Â±0.25 | 8.46Â±0.17  | 15.33Â±0.19 | 24.87Â±0.24 | 27.31Â±0.28 | 22.86Â±0.27 | 39.47Â±0.35 | 37.42Â±0.32 | 26.47Â±0.29 | 53.62Â±0.43 | 37.02Â±0.34 | 42.23Â±0.37 | 37.55Â±0.33 | 48.85Â±0.42 | 41.55Â±0.38 |
| UCMCTrack   | 17.27Â±0.21 | 24.33Â±0.26 | 12.32Â±0.19 | 18.43Â±0.22 | 18.72Â±0.17 | 26.56Â±0.24 | 13.22Â±0.18 | 39.45Â±0.34 | 28.80Â±0.23 | 22.49Â±0.21 | 37.03Â±0.31 | 34.55Â±0.29 | 31.00Â±0.27 | 30.95Â±0.25 | 31.17Â±0.28 | 42.80Â±0.36 |
| DiffMOT     | 24.02Â±0.29 | 26.16Â±0.31 | 22.14Â±0.28 | 26.98Â±0.33 | 25.06Â±0.26 | 27.85Â±0.29 | 22.57Â±0.27 | 38.84Â±0.35 | 38.92Â±0.34 | 22.81Â±0.23 | 66.48Â±0.53 | 44.27Â±0.41 | 44.42Â±0.39 | 30.52Â±0.28 | 64.66Â±0.51 | 55.90Â±0.47 |
| **MIMMA**   | 33.74Â±0.32 | 24.44Â±0.27 | 46.70Â±0.41 | 42.94Â±0.38 | 44.46Â±0.39 | 48.13Â±0.43 | 42.44Â±0.37 | 54.79Â±0.48 | 49.03Â±0.42 | 26.52Â±0.28 | 92.98Â±0.72 | 50.00Â±0.45 | 55.04Â±0.49 | 39.43Â±0.35 | 76.89Â±0.63 | 66.67Â±0.58 |

| Model       | MMTDS-satsot (HOTA/DetA/AssA/IDF1)         | MMTDS-viso (HOTA/DetA/AssA/IDF1)           | MMTDS-mtad (HOTA/DetA/AssA/IDF1)           | MMTDS-ais (HOTA/DetA/AssA/IDF1)            |
|-------------|--------------------------------------------|---------------------------------------------|---------------------------------------------|---------------------------------------------|
| ByteTrack   | 32.01Â±0.31 | 24.78Â±0.23 | 41.45Â±0.37 | 41.55Â±0.36 | 28.26Â±0.27 | 14.21Â±0.16 | 56.22Â±0.49 | 25.64Â±0.24 | 39.78Â±0.35 | 39.63Â±0.34 | 40.04Â±0.36 | 54.81Â±0.47 | 19.36Â±0.21 | 27.07Â±0.25 | 13.87Â±0.17 | 21.18Â±0.22 |
| OCSORT      | 41.68Â±0.38 | 30.54Â±0.29 | 57.01Â±0.51 | 44.37Â±0.40 | 27.09Â±0.26 | 14.45Â±0.15 | 50.78Â±0.45 | 23.89Â±0.23 | 30.43Â±0.28 | 38.93Â±0.35 | 23.89Â±0.24 | 43.89Â±0.39 | 14.86Â±0.16 | 31.68Â±0.28 | 6.98Â±0.09  | 26.61Â±0.25 |
| HybridSORT  | 42.76Â±0.39 | 32.23Â±0.31 | 56.97Â±0.52 | 44.85Â±0.41 | 27.96Â±0.26 | 14.45Â±0.14 | 54.09Â±0.48 | 24.25Â±0.22 | 24.03Â±0.23 | 31.96Â±0.29 | 18.17Â±0.19 | 33.92Â±0.31 | 14.25Â±0.15 | 30.33Â±0.27 | 6.70Â±0.08  | 25.07Â±0.24 |
| UCMCTrack   | 27.47Â±0.25 | 24.98Â±0.23 | 30.24Â±0.28 | 38.60Â±0.35 | 23.38Â±0.22 | 13.57Â±0.14 | 40.33Â±0.36 | 24.75Â±0.23 | 29.09Â±0.27 | 39.54Â±0.36 | 21.50Â±0.21 | 40.96Â±0.37 | 11.03Â±0.12 | 29.60Â±0.27 | 4.11Â±0.06  | 14.54Â±0.16 |
| DiffMOT     | 42.16Â±0.38 | 25.71Â±0.24 | 69.20Â±0.61 | 49.72Â±0.44 | 22.48Â±0.21 | 15.47Â±0.16 | 32.71Â±0.30 | 29.08Â±0.27 | 27.91Â±0.26 | 38.82Â±0.35 | 20.18Â±0.20 | 35.76Â±0.32 | 8.19Â±0.09  | 25.78Â±0.24 | 2.61Â±0.04  | 7.62Â±0.08  |
| **MIMMA**   | 42.37Â±0.39 | 18.95Â±0.18 | 94.74Â±0.83 | 33.33Â±0.30 | 61.95Â±0.55 | 72.49Â±0.67 | 53.08Â±0.47 | 73.10Â±0.65 | 40.73Â±0.37 | 42.44Â±0.38 | 39.33Â±0.35 | 53.43Â±0.48 | 22.74Â±0.23 | 31.77Â±0.29 | 16.31Â±0.18 | 30.18Â±0.28 |


### Citation
@article{anonymous2025mmmtta,<br>
  title     = {MMM-TTA: Multi-Probe Benchmark for Maritime Multi-Object Tracking},<br>
  author    = {Anonymous},<br>
  journal   = {NeurIPS},<br>
  year      = {2025},<br>
  note      = {Under Review}<br>
}
